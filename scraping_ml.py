# -*- coding: utf-8 -*-
"""Scraping ML.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Khk1upDb80gPevZZ4SVbhoNbKLd4hwFw
"""



from bs4 import BeautifulSoup
import requests
import pandas as pd
from lxml import etree

Buscar = "Asus TUF Gaming F15"
num_pages = 1

Next1 = ['https://listado.mercadolibre.com.co/',Buscar, '#D[A:',Buscar, ']']
Next = ''.join(Next1)

list_title = []
list_price = []

for _ in range(num_pages): # This will limit the number of pages
    result = requests.get(Next)
    if result.status_code == 200:
        soup = BeautifulSoup(result.content, "html.parser")

        title = soup.find_all("h2", class_="ui-search-item__title")
        title_ = [i.text for i in title]

        Var1 = etree.HTML(str(soup))

        price1=etree.HTML(str(soup))
        price = price1.xpath('//li[@class="ui-search-layout__item shops__layout-item ui-search-layout__stack"]//div[@class="ui-search-result__content-wrapper"]//div[@class="ui-search-result__content-columns"]//div[@class="ui-search-item__group ui-search-item__group--price ui-search-item__group--price-grid-container"]//div[@class="ui-search-price__second-line"]//span[@class="andes-money-amount ui-search-price__part ui-search-price__part--medium andes-money-amount--cents-superscript"]/span[2]')
        price_ = [i.text for i in price]

        min_len = min(len(price_), len(title_))
        list_price.extend(price_[:min_len])
        list_title.extend(title_[:min_len])

        try:
            Next = Var1.xpath('//div[@class="ui-search-main ui-search-main--only-products ui-search-main--with-topkeywords"]//section[@class="ui-search-results ui-search-results--without-disclaimer"]//nav//ul//li[contains(@class,"--next")]//a')[0].get('href')
        except IndexError:
            break
    else:
        print(f"Failed to get the content on page {_+1}...")
        break

df = pd.DataFrame({'price':list_price, 'title':list_title})
print(df)

df